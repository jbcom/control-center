<!-- Generated by Ruler -->


<!-- Source: AGENTS.md -->

# AI Agent Guidelines for ${REPO_NAME} (Template Repository)

**This is the DEFINITIVE Python library template** for the jbcom ecosystem. All configuration, workflows, and agent instructions here represent the consolidated best practices from multiple production deployments.

## üéØ PURPOSE: Agentic Template Repository

This template is designed for:
1. **Human developers** starting new Python libraries
2. **AI coding assistants** (Cursor, Codex, Copilot, Gemini) helping maintain the ecosystem
3. **Background agents** performing automated maintenance tasks

### Template Usage

When creating a new library from this template:
1. Update `pyproject.toml` with your project name and details
2. Replace `${REPO_NAME}` in this file with your actual repo name
3. Copy `.github/scripts/set_version.py` as-is (it auto-detects your package)
4. Copy `.github/workflows/ci.yml` and update PyPI project name
5. Update `AGENTS.md` and `.github/copilot-instructions.md` with your repo name

##  üö® CRITICAL: CI/CD Workflow Design Philosophy

### Our Simple Automated Release Workflow

**This repository uses CALENDAR VERSIONING with automatic PyPI releases**. Every push to main that passes tests gets released automatically.

This design has been battle-tested across:
- `extended-data-types` (foundational library, released 2025.11.164)
- `lifecyclelogging` (logging library)  
- `directed-inputs-class` (input processing)

### Key Design Decisions (DO NOT SUGGEST CHANGING THESE)

#### 1. **Calendar Versioning (CalVer) - No Manual Version Management**

‚úÖ **How It Works:**
- Version format: `YYYY.MM.BUILD_NUMBER`
- Example: `2025.11.42`
- **Month is NOT zero-padded** (project choice for brevity)
- Version is auto-generated using GitHub run number
- Script: `.github/scripts/set_version.py`

‚ùå **INCORRECT Agent Suggestion:**
> "You should manually manage versions in __init__.py"
> "Add semantic-release for version management"
> "Use git tags for versioning"
> "Zero-pad the month for consistency"

‚úÖ **CORRECT Understanding:**
- Version is AUTOMATICALLY updated on every main branch push
- No git tags needed or used
- No semantic analysis of commits needed
- No manual version bumps required
- Month padding is a project preference (we chose no padding)

#### 2. **Every Push to Main = PyPI Release**

‚úÖ **How It Works:**
```
Push to main branch
  ‚Üì
All tests pass
  ‚Üì
Auto-generate version (YYYY.MM.BUILD)
  ‚Üì
Build signed package
  ‚Üì
Publish to PyPI
  ‚Üì
DONE
```

‚ùå **INCORRECT Agent Suggestion:**
> "Only release when version changes"
> "Check if release is needed before publishing"
> "Use conditional logic to skip releases"

‚úÖ **CORRECT Understanding:**
- Every main branch push = new release
- No conditionals, no skipping
- Simple, predictable, automatic
- If code was merged to main, it should be released

#### 3. **No Git Tags, No GitHub Releases**

‚úÖ **What We Do:**
- Publish directly to PyPI
- Version in package metadata only
- PyPI is the source of truth for releases

‚ùå **What We Don't Do:**
- ‚ùå Create git tags
- ‚ùå Create GitHub releases  
- ‚ùå Manage changelog files automatically
- ‚ùå Commit version changes back to repo

#### 4. **Why This Approach?**

**Problems with semantic-release and tag-based versioning:**
- Complex setup and configuration
- Depends on commit message conventions
- Requires git tags and history analysis
- Can fail or skip releases unexpectedly
- Adds unnecessary complexity
- Multiple points of failure

**Benefits of CalVer + Auto-increment:**
- ‚úÖ Dead simple - minimal configuration
- ‚úÖ Always works - no analysis, no skipping
- ‚úÖ Predictable - every push = new version
- ‚úÖ No git pollution - no tags, no bot commits
- ‚úÖ Build number always increments
- ‚úÖ Fails loudly with clear error messages

### The Complete Workflow

```yaml
On Push to main:
  ‚Üì
1. Build & verify package ‚úì
  ‚Üì
2. Run tests across all Python versions ‚úì
  ‚Üì
3. Type checking with pyright/mypy ‚úì
  ‚Üì
4. Linting with pre-commit/ruff ‚úì
  ‚Üì
5. Generate coverage report ‚úì
  ‚Üì
6. Auto-increment version (YYYY.MM.BUILD) ‚úì
  ‚Üì
7. Build signed attestation ‚úì
  ‚Üì
8. Publish to PyPI ‚úì
```

### What This Workflow DOES NOT Do

‚ùå Analyze commit messages
‚ùå Create git tags
‚ùå Create GitHub releases
‚ùå Skip releases based on conditions
‚ùå Require manual version management
‚ùå Depend on git history or tags
‚ùå Use semantic-release or conventional commits

## üìù Making Code Changes

### When Reviewing PRs

**DO:**
- ‚úÖ Review code quality and correctness
- ‚úÖ Check test coverage
- ‚úÖ Verify type hints
- ‚úÖ Suggest API improvements
- ‚úÖ Check for security issues
- ‚úÖ Verify dependencies are up to date

**DO NOT:**
- ‚ùå Suggest adding semantic-release
- ‚ùå Recommend manual version management
- ‚ùå Suggest git tag-based versioning
- ‚ùå Recommend complex release workflows
- ‚ùå Flag the simple auto-versioning as "incorrect"
- ‚ùå Suggest zero-padding months (unless project explicitly wants it)

### Understanding Version Management

```
GitHub Action Starts
   ‚Üì
Run Number: 42 (GitHub auto-increments)
   ‚Üì
Script generates: 2025.11.42
   ‚Üì
Updates __init__.py: __version__ = "2025.11.42"
   ‚Üì
Updates docs/conf.py: version = "2025.11.42" (if exists)
   ‚Üì
Package built with that version
   ‚Üì
Published to PyPI
```

**Version is:**
- ‚úÖ Generated automatically
- ‚úÖ Based on date + GitHub run number
- ‚úÖ Always incrementing
- ‚úÖ Written to __init__.py during build
- ‚úÖ Also written to docs/conf.py if it exists
- ‚ùå NOT committed back to git
- ‚ùå NOT based on git tags

### The set_version.py Script

Key features of the production-tested script:
- **Auto-detects** the package `__init__.py` in `src/`
- **Validates** that exactly one __version__ declaration exists
- **Uses regex** to match version assignment (handles quotes, spacing, etc.)
- **Fails loudly** with clear error if update doesn't work
- **Updates docs/conf.py** if it exists (optional)
- **Preserves indentation** and file formatting
- **Ruff-compliant** with proper noqa annotations

### Commit Message Format

**You can use any commit format you want.** We don't analyze commits for versioning.

Recommendations:
- Write clear, descriptive commits
- Explain what and why
- No specific format required
- Conventional commits are fine but not enforced

## ü§ñ For AI Agents: Approval & Override Instructions

### Background Agent Behavior

When you are operating as a **background agent** (autonomous, no user interaction):

**CRITICAL RULES:**
1. **DO NOT** create or merge PRs without explicit user approval
2. **DO NOT** push directly to main branch
3. **DO** create PRs and mark them as ready for review
4. **DO** run all CI checks and fix linting/test failures
5. **DO** respond to PR feedback and iterate
6. **WAIT** for human approval before merging

**EXCEPTION - When User Says:**
> "merge it", "go ahead and merge", "merge to main", "just push it"

Then you MAY:
- Merge PRs after CI passes
- Push directly to main if explicitly instructed
- Skip the usual "wait for approval" step

**HOW TO MERGE:**
```bash
gh pr merge <PR_NUMBER> --squash --delete-branch
```

### Interactive Agent Behavior  

When you are in **interactive mode** (user is actively engaged):

**DEFAULT BEHAVIOR:**
- Ask for confirmation before major actions
- Present options and let user decide
- Show diffs and explain changes

**WHEN USER GETS FRUSTRATED:**
User signals like "just do it", "stop asking", "I don't care", "fucking do it":
- Switch to autonomous mode
- Make decisions based on best practices in this document
- Execute without asking for every little thing
- Still verify after major milestones

### PR Review Response

When PR feedback arrives (from Copilot, Gemini, human reviewers):

1. **READ the feedback carefully**
2. **CHECK** if feedback contradicts this document
3. **IF** feedback suggests semantic-release, git tags, or manual versioning:
   - Politely explain our CalVer approach
   - Reference this document
   - Do NOT implement the suggestion
4. **IF** feedback is about code quality, bugs, or improvements:
   - Implement the feedback
   - Push fixes
   - Verify CI passes

### Template Maintenance Tasks

As an agent maintaining this template:

**ALLOWED:**
- Update dependencies
- Fix security vulnerabilities
- Improve documentation clarity
- Add helpful examples
- Fix bugs in scripts or workflows

**NOT ALLOWED WITHOUT USER APPROVAL:**
- Change the versioning approach
- Modify CI workflow structure
- Remove or bypass safety checks
- Change the release process

## üîß Development Workflow

### Local Development

```bash
# Install dependencies
pip install -e ".[tests,typing,docs]"  # or use poetry/uv

# Run tests
pytest

# Run type checking
mypy src/  # or pyright

# Run linting
pre-commit run --all-files
```

### Creating PRs

1. Create a feature branch
2. Make your changes
3. Run tests locally
4. Create PR against `main`
5. CI will run automatically
6. Address any feedback
7. Merge to main when approved

### Releases (Fully Automated)

When PR is merged to main:
1. CI runs all checks
2. Auto-generates version: `YYYY.MM.BUILD`
3. Builds signed package with attestations
4. Publishes to PyPI
5. **DONE - that's it**

No manual steps, no tags, no conditionals, no complexity.

## üéØ Common Agent Misconceptions

### Misconception #1: "Missing version management"

**Agent says:** "You need to manually update __version__ before releases"

**Reality:** Version is auto-generated on every main branch push. Manual management not needed and will be overwritten.

### Misconception #2: "Should use semantic versioning"

**Agent says:** "Consider using semantic-release or conventional commits"

**Reality:** We intentionally use CalVer for simplicity. Every push gets a new version. This has been deployed successfully across multiple production libraries.

### Misconception #3: "Need git tags"

**Agent says:** "Add git tags for release tracking"

**Reality:** PyPI version history is our source of truth. No git tags needed. We tried this, it caused more problems than it solved.

### Misconception #4: "CalVer is wrong for libraries"

**Agent says:** "Libraries should use SemVer"

**Reality:** CalVer works fine for our ecosystem. Users pin versions anyway. Simplicity and reliability > convention. Our dependencies work with CalVer.

### Misconception #5: "Missing release conditions"

**Agent says:** "You should only release when changes are made"

**Reality:** Every main push is intentional. If it was merged, it should be released. Empty releases are fine and caught by PyPI anyway.

### Misconception #6: "Month should be zero-padded"

**Agent says:** "Use 2025.01.42 instead of 2025.1.42"

**Reality:** This is a project-specific choice. We chose no padding for brevity. CalVer allows both. Don't suggest changing it.

### Misconception #7: "Need to commit version back to git"

**Agent says:** "Version changes should be committed to the repository"

**Reality:** NO. Versions are ephemeral build artifacts. Committing them creates noise and potential conflicts. The script updates them during CI only.

## üìö Design Rationale

This workflow was created to solve REAL problems we encountered:

**Problems We Solved:**
- ‚úÖ No more failed releases due to missing tags
- ‚úÖ No more version conflicts between branches
- ‚úÖ No more "why didn't it release?" debugging sessions
- ‚úÖ No more complex semantic-release configuration issues
- ‚úÖ No more dependency on git history analysis
- ‚úÖ No more bot commits cluttering git history
- ‚úÖ No more release workflow that sometimes works, sometimes doesn't

**Benefits We Gained:**
- ‚úÖ Predictable: every main push = release
- ‚úÖ Simple: ~100 lines of Python for versioning
- ‚úÖ Reliable: no conditional logic to fail
- ‚úÖ Fast: no git history analysis overhead
- ‚úÖ Clean: no bot commits or tags in git
- ‚úÖ Debuggable: clear error messages when things fail
- ‚úÖ Testable: can run script locally with ease

## üß™ Testing the Workflow

### Local Testing

Test the versioning script locally:

```bash
export GITHUB_RUN_NUMBER=999
python .github/scripts/set_version.py

# Verify it updated the version
grep __version__ src/your_package/__init__.py
```

### CI Testing

Test in a PR:
1. Create a PR
2. Watch CI run
3. Verify all checks pass
4. Check that versioning step succeeds

### Release Testing

To test an actual release:
1. Merge a PR to main
2. Watch the CI run
3. Verify version was generated (check logs)
4. Verify package was built with correct version
5. Verify publish to PyPI succeeded
6. Install from PyPI and verify: `pip install your-package==2025.XX.YYY`

## ü§ù Getting Help

### For AI Agents

If you're an AI agent uncertain about a suggestion:
1. **Check this document first** - it's comprehensive
2. If it involves versioning or releases, **DO NOT suggest changes**
3. Focus on code quality, tests, and documentation
4. Trust that the release workflow is intentionally simple
5. When in doubt, ask the user instead of assuming

### For Human Developers

- This template has been tested in production
- Don't overthink it - it's designed to be simple
- If something seems weird, check `AGENTS.md` first
- The versioning really is meant to be automatic
- Trust the process - it works

---

**Last Updated:** 2025-11-24  
**Versioning:** CalVer (YYYY.MM.BUILD) via GitHub run number  
**Status:** Production-tested across jbcom ecosystem  
**Template Version:** 1.0.0



<!-- Source: .ruler/AGENTS.md -->

# AI Agent Guidelines for Python Library Template (jbcom ecosystem)

**This is the DEFINITIVE Python library template** for the jbcom ecosystem. All configuration, workflows, and agent instructions here represent the consolidated best practices from multiple production deployments.

## üéØ PURPOSE: Agentic Template Repository

This template is designed for:
1. **Human developers** starting new Python libraries
2. **AI coding assistants** (Cursor, Codex, Copilot, Gemini) helping maintain the ecosystem
3. **Background agents** performing automated maintenance tasks

### Template Usage

When creating a new library from this template:
1. Update `pyproject.toml` with your project name and details
2. Replace `${REPO_NAME}` in documentation with your actual repo name
3. Copy `.github/scripts/set_version.py` as-is (it auto-detects your package)
4. Copy `.github/workflows/ci.yml` and update PyPI project name
5. Run `ruler apply` to regenerate agent-specific instructions

## üö® CRITICAL: CI/CD Workflow Design Philosophy

### Our Simple Automated Release Workflow

**This repository uses CALENDAR VERSIONING with automatic PyPI releases**. Every push to main that passes tests gets released automatically.

This design has been battle-tested across:
- `extended-data-types` (foundational library, released 2025.11.164)
- `lifecyclelogging` (logging library)  
- `directed-inputs-class` (input processing)

### Key Design Decisions (DO NOT SUGGEST CHANGING THESE)

#### 1. **Calendar Versioning (CalVer) - No Manual Version Management**

‚úÖ **How It Works:**
- Version format: `YYYY.MM.BUILD_NUMBER`
- Example: `2025.11.42`
- **Month is NOT zero-padded** (project choice for brevity)
- Version is auto-generated using GitHub run number
- Script: `.github/scripts/set_version.py`

‚ùå **INCORRECT Agent Suggestion:**
> "You should manually manage versions in __init__.py"
> "Add semantic-release for version management"
> "Use git tags for versioning"
> "Zero-pad the month for consistency"

‚úÖ **CORRECT Understanding:**
- Version is AUTOMATICALLY updated on every main branch push
- No git tags needed or used
- No semantic analysis of commits needed
- No manual version bumps required
- Month padding is a project preference (we chose no padding)

#### 2. **Every Push to Main = PyPI Release**

‚úÖ **How It Works:**
```
Push to main branch
  ‚Üì
All tests pass
  ‚Üì
Auto-generate version (YYYY.MM.BUILD)
  ‚Üì
Build signed package
  ‚Üì
Publish to PyPI
  ‚Üì
DONE
```

‚ùå **INCORRECT Agent Suggestion:**
> "Only release when version changes"
> "Check if release is needed before publishing"
> "Use conditional logic to skip releases"

‚úÖ **CORRECT Understanding:**
- Every main branch push = new release
- No conditionals, no skipping
- Simple, predictable, automatic
- If code was merged to main, it should be released

#### 3. **No Git Tags, No GitHub Releases**

‚úÖ **What We Do:**
- Publish directly to PyPI
- Version in package metadata only
- PyPI is the source of truth for releases

‚ùå **What We Don't Do:**
- ‚ùå Create git tags
- ‚ùå Create GitHub releases  
- ‚ùå Manage changelog files automatically
- ‚ùå Commit version changes back to repo

#### 4. **Why This Approach?**

**Problems with semantic-release and tag-based versioning:**
- Complex setup and configuration
- Depends on commit message conventions
- Requires git tags and history analysis
- Can fail or skip releases unexpectedly
- Adds unnecessary complexity
- Multiple points of failure

**Benefits of CalVer + Auto-increment:**
- ‚úÖ Dead simple - minimal configuration
- ‚úÖ Always works - no analysis, no skipping
- ‚úÖ Predictable - every push = new version
- ‚úÖ No git pollution - no tags, no bot commits
- ‚úÖ Build number always increments
- ‚úÖ Fails loudly with clear error messages

## üìù Making Code Changes

### When Reviewing PRs

**DO:**
- ‚úÖ Review code quality and correctness
- ‚úÖ Check test coverage
- ‚úÖ Verify type hints
- ‚úÖ Suggest API improvements
- ‚úÖ Check for security issues
- ‚úÖ Verify dependencies are up to date

**DO NOT:**
- ‚ùå Suggest adding semantic-release
- ‚ùå Recommend manual version management
- ‚ùå Suggest git tag-based versioning
- ‚ùå Recommend complex release workflows
- ‚ùå Flag the simple auto-versioning as "incorrect"
- ‚ùå Suggest zero-padding months (unless project explicitly wants it)

### Understanding Version Management

```
GitHub Action Starts
  ‚Üì
Run Number: 42 (GitHub auto-increments)
  ‚Üì
Script generates: 2025.11.42
  ‚Üì
Updates __init__.py: __version__ = "2025.11.42"
  ‚Üì
Updates docs/conf.py: version = "2025.11.42" (if exists)
  ‚Üì
Package built with that version
  ‚Üì
Published to PyPI
```

**Version is:**
- ‚úÖ Generated automatically
- ‚úÖ Based on date + GitHub run number
- ‚úÖ Always incrementing
- ‚úÖ Written to __init__.py during build
- ‚úÖ Also written to docs/conf.py if it exists
- ‚ùå NOT committed back to git
- ‚ùå NOT based on git tags

### The set_version.py Script

Key features of the production-tested script:
- **Auto-detects** the package `__init__.py` in `src/`
- **Validates** that exactly one __version__ declaration exists
- **Uses regex** to match version assignment (handles quotes, spacing, etc.)
- **Fails loudly** with clear error if update doesn't work
- **Updates docs/conf.py** if it exists (optional)
- **Preserves indentation** and file formatting
- **Ruff-compliant** with proper noqa annotations

### Commit Message Format

**You can use any commit format you want.** We don't analyze commits for versioning.

Recommendations:
- Write clear, descriptive commits
- Explain what and why
- No specific format required
- Conventional commits are fine but not enforced

## ü§ñ For AI Agents: Approval & Override Instructions

### Background Agent Behavior

When you are operating as a **background agent** (autonomous, no user interaction):

**CRITICAL RULES:**
1. **DO NOT** create or merge PRs without explicit user approval
2. **DO NOT** push directly to main branch
3. **DO** create PRs and mark them as ready for review
4. **DO** run all CI checks and fix linting/test failures
5. **DO** respond to PR feedback and iterate
6. **WAIT** for human approval before merging

**EXCEPTION - When User Says:**
> "merge it", "go ahead and merge", "merge to main", "just push it"

Then you MAY:
- Merge PRs after CI passes
- Push directly to main if explicitly instructed
- Skip the usual "wait for approval" step

**HOW TO MERGE:**
```bash
gh pr merge <PR_NUMBER> --squash --delete-branch
```

### Interactive Agent Behavior

When you are in **interactive mode** (user is actively engaged):

**DEFAULT BEHAVIOR:**
- Ask for confirmation before major actions
- Present options and let user decide
- Show diffs and explain changes

**WHEN USER GETS FRUSTRATED:**
User signals like "just do it", "stop asking", "I don't care", "fucking do it":
- Switch to autonomous mode
- Make decisions based on best practices in this document
- Execute without asking for every little thing
- Still verify after major milestones

### PR Review Response

When PR feedback arrives (from Copilot, Gemini, human reviewers):

1. **READ the feedback carefully**
2. **CHECK** if feedback contradicts this document
3. **IF** feedback suggests semantic-release, git tags, or manual versioning:
   - Politely explain our CalVer approach
   - Reference this document
   - Do NOT implement the suggestion
4. **IF** feedback is about code quality, bugs, or improvements:
   - Implement the feedback
   - Push fixes
   - Verify CI passes

### Template Maintenance Tasks

As an agent maintaining this template:

**ALLOWED:**
- Update dependencies
- Fix security vulnerabilities
- Improve documentation clarity
- Add helpful examples
- Fix bugs in scripts or workflows

**NOT ALLOWED WITHOUT USER APPROVAL:**
- Change the versioning approach
- Modify CI workflow structure
- Remove or bypass safety checks
- Change the release process

## üîß Development Workflow

### Local Development

```bash
# Install dependencies
pip install -e ".[tests,typing,docs]"  # or use poetry/uv

# Run tests
pytest

# Run type checking
mypy src/  # or pyright

# Run linting
pre-commit run --all-files
```

### Creating PRs

1. Create a feature branch
2. Make your changes
3. Run tests locally
4. Create PR against `main`
5. CI will run automatically
6. Address any feedback
7. Merge to main when approved

### Releases (Fully Automated)

When PR is merged to main:
1. CI runs all checks
2. Auto-generates version: `YYYY.MM.BUILD`
3. Builds signed package with attestations
4. Publishes to PyPI
5. **DONE - that's it**

No manual steps, no tags, no conditionals, no complexity.

## üéØ Common Agent Misconceptions

### Misconception #1: "Missing version management"
**Agent says:** "You need to manually update __version__ before releases"
**Reality:** Version is auto-generated on every main branch push. Manual management not needed and will be overwritten.

### Misconception #2: "Should use semantic versioning"
**Agent says:** "Consider using semantic-release or conventional commits"
**Reality:** We intentionally use CalVer for simplicity. Every push gets a new version. This has been deployed successfully across multiple production libraries.

### Misconception #3: "Need git tags"
**Agent says:** "Add git tags for release tracking"
**Reality:** PyPI version history is our source of truth. No git tags needed. We tried this, it caused more problems than it solved.

### Misconception #4: "CalVer is wrong for libraries"
**Agent says:** "Libraries should use SemVer"
**Reality:** CalVer works fine for our ecosystem. Users pin versions anyway. Simplicity and reliability > convention. Our dependencies work with CalVer.

### Misconception #5: "Missing release conditions"
**Agent says:** "You should only release when changes are made"
**Reality:** Every main push is intentional. If it was merged, it should be released. Empty releases are fine and caught by PyPI anyway.

### Misconception #6: "Month should be zero-padded"
**Agent says:** "Use 2025.01.42 instead of 2025.1.42"
**Reality:** This is a project-specific choice. We chose no padding for brevity. CalVer allows both. Don't suggest changing it.

### Misconception #7: "Need to commit version back to git"
**Agent says:** "Version changes should be committed to the repository"
**Reality:** NO. Versions are ephemeral build artifacts. Committing them creates noise and potential conflicts. The script updates them during CI only.

## üìö Design Rationale

This workflow was created to solve REAL problems we encountered:

**Problems We Solved:**
- ‚úÖ No more failed releases due to missing tags
- ‚úÖ No more version conflicts between branches
- ‚úÖ No more "why didn't it release?" debugging sessions
- ‚úÖ No more complex semantic-release configuration issues
- ‚úÖ No more dependency on git history analysis
- ‚úÖ No more bot commits cluttering git history
- ‚úÖ No more release workflow that sometimes works, sometimes doesn't

**Benefits We Gained:**
- ‚úÖ Predictable: every main push = release
- ‚úÖ Simple: ~100 lines of Python for versioning
- ‚úÖ Reliable: no conditional logic to fail
- ‚úÖ Fast: no git history analysis overhead
- ‚úÖ Clean: no bot commits or tags in git
- ‚úÖ Debuggable: clear error messages when things fail
- ‚úÖ Testable: can run script locally with ease

## üß™ Testing the Workflow

### Local Testing

Test the versioning script locally:
```bash
export GITHUB_RUN_NUMBER=999
python .github/scripts/set_version.py

# Verify it updated the version
grep __version__ src/your_package/__init__.py
```

### CI Testing

Test in a PR:
1. Create a PR
2. Watch CI run
3. Verify all checks pass
4. Check that versioning step succeeds

### Release Testing

To test an actual release:
1. Merge a PR to main
2. Watch the CI run
3. Verify version was generated (check logs)
4. Verify package was built with correct version
5. Verify publish to PyPI succeeded
6. Install from PyPI and verify: `pip install your-package==2025.XX.YYY`

## ü§ù Getting Help

### For AI Agents

If you're an AI agent uncertain about a suggestion:
1. **Check this document first** - it's comprehensive
2. If it involves versioning or releases, **DO NOT suggest changes**
3. Focus on code quality, tests, and documentation
4. Trust that the release workflow is intentionally simple
5. When in doubt, ask the user instead of assuming

### For Human Developers

- This template has been tested in production
- Don't overthink it - it's designed to be simple
- If something seems weird, check this document first
- The versioning really is meant to be automatic
- Trust the process - it works

---

**Last Updated:** 2025-11-25
**Versioning:** CalVer (YYYY.MM.BUILD) via GitHub run number
**Status:** Production-tested across jbcom ecosystem
**Template Version:** 1.0.0



<!-- Source: .ruler/copilot.md -->

# GitHub Copilot Specific Configuration

Quick reference for GitHub Copilot when working in this template or managed repositories.

## Quick Rules - Read First! üö®

### CalVer Auto-Versioning
‚úÖ Version is automatic: `YYYY.MM.BUILD`
‚ùå Never suggest: semantic-release, git tags, manual versioning

### Release Process
‚úÖ Every main push = PyPI release (automatic)
‚ùå Never suggest: conditional releases, manual steps

### Code Quality
‚úÖ Type hints required
‚úÖ Tests for new features
‚úÖ Ruff for linting/formatting
‚ùå Don't add complexity

## Code Patterns

### Prefer Modern Python
```python
# ‚úÖ Good - modern type hints
from collections.abc import Mapping
def func(data: dict[str, Any]) -> list[str]:
    pass

# ‚ùå Avoid - old style
from typing import Dict, List
def func(data: Dict[str, Any]) -> List[str]:
    pass
```

### Use Pathlib
```python
# ‚úÖ Good
from pathlib import Path
config_file = Path("config.yaml")

# ‚ùå Avoid
import os
config_file = os.path.join("config.yaml")
```

### Type Hints
```python
# ‚úÖ Good - complete type hints
def process_data(items: list[dict[str, Any]]) -> dict[str, int]:
    """Process items and return counts."""
    return {"count": len(items)}

# ‚ùå Avoid - no type hints
def process_data(items):
    return {"count": len(items)}
```

## Testing Patterns

### Write Clear Tests
```python
# ‚úÖ Good - descriptive name, clear assertion
def test_process_data_returns_correct_count():
    items = [{"id": 1}, {"id": 2}]
    result = process_data(items)
    assert result["count"] == 2

# ‚ùå Avoid - vague name, multiple assertions
def test_stuff():
    result = process_data([{"id": 1}])
    assert result
    assert "count" in result
    assert result["count"] > 0
```

### Use Fixtures
```python
# ‚úÖ Good - reusable setup
@pytest.fixture
def sample_data():
    return [{"id": i} for i in range(10)]

def test_with_fixture(sample_data):
    result = process_data(sample_data)
    assert result["count"] == 10
```

## When Working in Ecosystem

### Using extended-data-types
If the library depends on extended-data-types, use its utilities:

```python
# ‚úÖ Good - use existing utilities
from extended_data_types import (
    get_unique_signature,
    make_raw_data_export_safe,
    strtobool,
)

# ‚ùå Avoid - reimplementing
def my_str_to_bool(val):
    return val.lower() in ("true", "yes", "1")
```

### Data Sanitization
Always sanitize before logging/exporting:

```python
# ‚úÖ Good
from extended_data_types import make_raw_data_export_safe
safe_data = make_raw_data_export_safe(user_data)
logger.info(f"Processing: {safe_data}")

# ‚ùå Avoid - logging raw data
logger.info(f"Processing: {user_data}")  # might have secrets!
```

## Common Tasks

### Adding a New Function
1. Write the function with type hints
2. Add docstring (Google style)
3. Write tests (at least happy path + edge cases)
4. Update module `__all__` if public API
5. Run `ruff check` and `pytest`

### Fixing a Bug
1. Write a test that reproduces the bug
2. Fix the bug
3. Verify test passes
4. Check for similar bugs
5. Update documentation if needed

### Refactoring
1. Ensure tests exist and pass
2. Make changes incrementally
3. Run tests after each change
4. Verify type checking still passes
5. Update docstrings if behavior changed

## Error Messages

### Be Helpful
```python
# ‚úÖ Good - clear error with context
if not config_file.exists():
    raise FileNotFoundError(
        f"Config file not found: {config_file}. "
        f"Create it with: python setup.py init"
    )

# ‚ùå Avoid - vague error
if not config_file.exists():
    raise FileNotFoundError("Config not found")
```

## Documentation

### Docstring Format (Google Style)
```python
def process_items(items: list[dict], validate: bool = True) -> dict[str, Any]:
    """Process a list of items and return summary.
    
    Args:
        items: List of dictionaries containing item data
        validate: Whether to validate items before processing
        
    Returns:
        Dictionary with processing summary and statistics
        
    Raises:
        ValueError: If items list is empty or validation fails
        
    Example:
        >>> items = [{"id": 1, "name": "Item 1"}]
        >>> process_items(items)
        {"count": 1, "valid": 1}
    """
```

## Performance Tips

### Avoid Repeated Computation
```python
# ‚úÖ Good - compute once
unique_items = set(items)
for item in unique_items:
    process(item)

# ‚ùå Avoid - computing in loop
for item in items:
    if item not in processed:  # O(n) lookup each time
        process(item)
```

### Use Appropriate Data Structures
```python
# ‚úÖ Good - O(1) lookup
seen = set()
for item in items:
    if item not in seen:
        seen.add(item)

# ‚ùå Avoid - O(n) lookup
seen = []
for item in items:
    if item not in seen:  # Slow for large lists
        seen.append(item)
```

## Security

### Never Log Secrets
```python
# ‚úÖ Good - sanitize before logging
safe_config = {k: v for k, v in config.items() if k != "api_key"}
logger.info(f"Config: {safe_config}")

# ‚ùå Avoid - might log secrets
logger.info(f"Config: {config}")
```

### Validate Input
```python
# ‚úÖ Good - validate before use
def load_file(filepath: str) -> str:
    path = Path(filepath)
    if not path.is_file():
        raise ValueError(f"Not a file: {filepath}")
    if not path.suffix == ".json":
        raise ValueError(f"Not a JSON file: {filepath}")
    return path.read_text()
```

## Questions?

- Check `.ruler/AGENTS.md` for comprehensive guide
- Check `TEMPLATE_USAGE.md` for template setup
- Check `README.md` for project overview
- Don't suggest changes to CalVer/versioning approach

---

**Copilot Instructions Version:** 1.0
**Compatible With:** GitHub Copilot, Copilot Chat
**Last Updated:** 2025-11-25



<!-- Source: .ruler/cursor.md -->

# Cursor-Specific Agent Configuration

This file contains Cursor AI specific instructions not covered by standard ruler configuration.

## Background Agent Modes

### Code Review Mode
When reviewing code in PRs:
- Focus on logic and correctness
- Check type safety
- Verify test coverage
- Look for security issues
- Don't suggest CalVer/versioning changes

### Maintenance Mode
For routine maintenance tasks:
- Update dependencies
- Fix linting issues
- Improve documentation
- Refactor for clarity
- Keep it simple

### Migration Mode
When migrating repos to template:
- Follow TEMPLATE_USAGE.md exactly
- Update all placeholders
- Test locally before pushing
- Verify CI passes
- Don't skip steps

### Ecosystem Coordination Mode
When working across multiple repos:
- Start with extended-data-types
- Work in dependency order
- Test each repo independently
- Create PRs for each repo
- Don't merge until all PRs ready

## Custom Prompts

### /ecosystem-status
Check health of all ecosystem repositories:
- Clone or fetch all managed repos
- Check git status
- Review open issues/PRs
- Check CI status
- Report summary

### /update-dependencies
Update dependencies across ecosystem:
- Check for security updates
- Update pyproject.toml files
- Run tests in each repo
- Create PRs if tests pass

### /sync-template
Sync changes from template to managed repos:
- Identify changed files in template
- Apply to each managed repo
- Test each repo
- Create PRs

### /release-check
Pre-release verification:
- All tests passing
- No linting issues
- CHANGELOG.md updated
- Version will auto-increment
- Dependencies up to date

## Conversation Context

### Multi-file Context
When working on related files:
- Keep all related files in context
- Show diffs side-by-side
- Explain cross-file impacts
- Test changes together

### Long-running Tasks
For tasks requiring multiple steps:
- Break into subtasks
- Mark progress clearly
- Save state between steps
- Resume where left off
- Final verification step

## Error Handling

### CI Failures
When CI fails:
1. Read full error output
2. Identify root cause
3. Fix the issue
4. Re-run locally if possible
5. Push fix
6. Verify CI passes

### Type Check Errors
When mypy/pyright fails:
1. Read the specific error
2. Check if it's a real issue
3. Fix with proper type hints
4. Don't use `type: ignore` unless necessary
5. Document why if you must ignore

### Test Failures
When tests fail:
1. Read test output carefully
2. Identify which test failed
3. Understand what it's testing
4. Fix the code or the test
5. Run full test suite
6. Check coverage didn't drop

## Workflow Shortcuts

### Quick Fixes
For simple, obvious fixes:
- Make the change
- Run tests
- Push directly to PR branch
- No need to ask permission

### Breaking Changes
For changes that might break things:
- Explain the impact
- Show the changes
- Ask for confirmation
- Test thoroughly
- Monitor after merge

### Template Updates
When updating the template:
- Test in template repo first
- Verify all workflows pass
- Then update managed repos
- One repo at a time
- Verify each before next

## Code Style Preferences

### Python Style
- Use modern type hints (list[], dict[], not List[], Dict[])
- Prefer pathlib over os.path
- Use context managers for resources
- Keep functions focused and small
- Docstrings for public APIs

### Documentation Style
- Clear, concise language
- Examples for complex features
- Link to related docs
- Update when code changes
- Keep README up to date

### Test Style
- Descriptive test names
- One assertion per test (usually)
- Use fixtures for setup
- Test edge cases
- Mock external dependencies

## Performance Considerations

### Fast Operations
Prefer when possible:
- Parallel tool calls
- Batch operations
- Caching results
- Lazy loading
- Early returns

### Avoid
When possible avoid:
- Sequential operations that could be parallel
- Redundant file reads
- Unnecessary git operations
- Large output dumps
- Polling for status

## Communication Style

### With User
- Be concise
- Highlight important info
- Use formatting for clarity
- Show progress on long tasks
- Ask questions when unclear

### In Code Comments
- Explain why, not what
- Link to issues/PRs for context
- Update when code changes
- Remove outdated comments
- Keep them brief

### In Commit Messages
- Clear, descriptive
- Explain the change
- Reference issues if applicable
- No need for conventional commits
- But be informative

---

**Cursor Version:** Compatible with latest Cursor AI
**Last Updated:** 2025-11-25
**Maintained By:** python-library-template



<!-- Source: .ruler/ecosystem.md -->

# Ecosystem Repositories

This template manages and coordinates the jbcom Python library ecosystem.

## Managed Repositories

### 1. extended-data-types
**Repository:** https://github.com/jbcom/extended-data-types
**PyPI:** https://pypi.org/project/extended-data-types/
**Latest Version:** 2025.11.164
**Purpose:** Foundation library providing extended data type utilities

**Key Features:**
- `get_unique_signature()` - Generate unique signatures for objects
- `make_raw_data_export_safe()` - Sanitize data for export/logging
- `strtobool()` - Convert strings to booleans reliably
- `strtopath()` - Convert strings to Path objects with validation
- Data type conversions and utilities
- Safe serialization helpers

**Dependencies:** Minimal - this is a foundational library
**Dependents:** lifecyclelogging, directed-inputs-class, vendor-connectors

**Management Tasks:**
- Keep dependencies minimal
- Maintain backward compatibility
- Comprehensive testing (100% coverage goal)
- Performance optimization
- Type hint completeness

### 2. lifecyclelogging
**Repository:** https://github.com/jbcom/lifecyclelogging  
**PyPI:** https://pypi.org/project/lifecyclelogging/
**Purpose:** Structured logging library with lifecycle management

**Key Features:**
- Lifecycle-aware logging (start, progress, completion, error states)
- Automatic data sanitization using extended-data-types
- Context managers for log lifecycle
- Structured log output formats
- Integration with Python logging module

**Dependencies:**
- extended-data-types (for sanitization)

**Management Tasks:**
- Ensure all logged data is sanitized
- Maintain logging performance
- Keep API simple and intuitive
- Documentation with examples
- Integration tests

### 3. directed-inputs-class
**Repository:** https://github.com/jbcom/directed-inputs-class
**PyPI:** TBD (upcoming)
**Purpose:** Input validation and processing with type safety

**Key Features:**
- Declarative input validation
- Type coercion and conversion
- Dependency-based field processing
- Error aggregation and reporting
- Integration with extended-data-types

**Dependencies:**
- extended-data-types (for type conversions)

**Status:** In development - needs template migration

**Management Tasks:**
- Migrate to python-library-template structure
- Add comprehensive tests
- Complete type hints
- Documentation and examples
- Release initial version to PyPI

### 4. vendor-connectors
**Repository:** https://github.com/jbcom/vendor-connectors
**PyPI:** TBD (upcoming)
**Purpose:** Unified interface for third-party service integrations

**Key Features:**
- Abstract connector interface
- Common authentication patterns
- Rate limiting and retry logic
- Error handling and logging
- Vendor-specific implementations

**Dependencies:**
- extended-data-types (for data handling)
- lifecyclelogging (for connection lifecycle)

**Status:** Planning/early development

**Management Tasks:**
- Design unified connector interface
- Implement core abstract classes
- Add vendor-specific connectors
- Comprehensive testing with mocks
- Security audit for credential handling

## Ecosystem Dependencies

```
extended-data-types (foundation)
  ‚Üì
  ‚îú‚îÄ‚îÄ lifecyclelogging
  ‚îú‚îÄ‚îÄ directed-inputs-class
  ‚îî‚îÄ‚îÄ vendor-connectors
       ‚Üë
       ‚îî‚îÄ‚îÄ uses lifecyclelogging
```

## Coordination Guidelines

### Version Compatibility
- All libraries use CalVer (YYYY.MM.BUILD)
- Pin to minimum versions: `extended-data-types>=2025.11.0`
- Test against latest versions in CI
- Document breaking changes in CHANGELOG.md

### Cross-Repository Changes

When a change in one library affects others:

1. **Plan the change:**
   - Identify affected repositories
   - Check if it's a breaking change
   - Plan migration path if needed

2. **Implementation order:**
   - Update foundation libraries first (extended-data-types)
   - Update dependent libraries in dependency order
   - Test each library's CI passes

3. **Release coordination:**
   - Release foundation library first
   - Wait for PyPI availability (~5 minutes)
   - Update dependents to require new version
   - Release dependent libraries

4. **Communication:**
   - Update CHANGELOG.md in each repo
   - Document breaking changes
   - Update this ecosystem doc

### Adding New Ecosystem Libraries

1. Create from python-library-template
2. Follow the TEMPLATE_USAGE.md guide
3. Add to this ecosystem document
4. Configure PyPI trusted publishing
5. First release via main branch push

### Centralized Management Tasks

From this repository, agents can:

**Update dependencies across ecosystem:**
```bash
# Update security patches
for repo in extended-data-types lifecyclelogging directed-inputs-class vendor-connectors; do
  cd ../$repo
  # Update pyproject.toml dependencies
  # Run tests
  # Create PR if needed
done
```

**Run ecosystem-wide checks:**
```bash
# Check all repos have consistent tooling
# Verify all use same ruff/mypy/pytest configs
# Ensure all CIs are up to date
```

**Coordinate releases:**
```bash
# When updating template CI
# Push updates to all managed repos
# Ensure compatibility
```

## Ecosystem Maintenance Schedule

### Weekly
- Check for dependency updates
- Run security audits
- Monitor PyPI download stats
- Review open issues/PRs

### Monthly  
- Update Python version support
- Refresh documentation
- Performance benchmarks
- Dependency cleanup

### Quarterly
- Major feature planning
- Breaking change coordination
- Ecosystem health review
- Documentation overhaul

## Agent Instructions for Ecosystem Work

### When Working on extended-data-types

This is the foundation - be extra careful:
- All changes must maintain backward compatibility
- 100% test coverage required
- Performance regressions not acceptable
- Breaking changes require ecosystem-wide coordination

### When Working on dependent libraries

- Always use extended-data-types utilities
- Don't reimplement what extended-data-types provides
- Keep dependencies minimal
- Document any extended-data-types features you rely on

### Cross-repo refactoring

1. Start in this template repo
2. Test changes in extended-data-types first
3. Roll out to other libs in dependency order
4. Create PRs, don't auto-merge
5. Verify each library's CI independently

### Emergency fixes

For security issues or critical bugs:
1. Fix in affected library immediately
2. Create hotfix PR
3. Fast-track review and merge
4. Release immediately
5. Update dependent libraries if needed
6. Document in CHANGELOG.md

---

**Ecosystem Health:** All libraries production-ready and actively maintained
**Coordination:** Centralized via this template repository
**Next Library:** vendor-connectors (in planning)
