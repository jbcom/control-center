# Unified CI/CD workflow for jbcom control center
# 
# On PR:      Test â†’ Lint â†’ Build docs (verify)
# On main:    Test â†’ Lint â†’ Build docs â†’ Sync â†’ Release â†’ Deploy docs
#
# Everything in one place, dependency-aware, efficient.

name: CI

on:
  push:
    branches: [main]
  pull_request:
  workflow_dispatch:
    inputs:
      force_release:
        description: 'Force release even without changes'
        type: boolean
        default: false

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.13'
  DOCS_REPO: 'jbcom/jbcom-docs'  # Where to push docs

jobs:
  # ============================================
  # DETECT CHANGES
  # ============================================
  changes:
    runs-on: ubuntu-latest
    outputs:
      packages: ${{ steps.detect.outputs.packages }}
      any_changed: ${{ steps.detect.outputs.any_changed }}
      docs_changed: ${{ steps.detect.outputs.docs_changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changes
        id: detect
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            # Manual trigger - run everything
            echo 'packages=["extended-data-types","lifecyclelogging","directed-inputs-class","vendor-connectors"]' >> $GITHUB_OUTPUT
            echo "any_changed=true" >> $GITHUB_OUTPUT
            echo "docs_changed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            BASE="${{ github.event.pull_request.base.sha }}"
          else
            BASE="${{ github.event.before }}"
          fi
          
          # Check what changed
          CHANGED_FILES=$(git diff --name-only $BASE HEAD 2>/dev/null || echo "")
          
          PACKAGES=""
          DOCS_CHANGED="false"
          
          # Foundation changed = test everything
          if echo "$CHANGED_FILES" | grep -q "^packages/extended-data-types/"; then
            PACKAGES="extended-data-types lifecyclelogging directed-inputs-class vendor-connectors"
          else
            if echo "$CHANGED_FILES" | grep -q "^packages/lifecyclelogging/"; then
              PACKAGES="$PACKAGES lifecyclelogging vendor-connectors"
            fi
            if echo "$CHANGED_FILES" | grep -q "^packages/directed-inputs-class/"; then
              PACKAGES="$PACKAGES directed-inputs-class"
            fi
            if echo "$CHANGED_FILES" | grep -q "^packages/vendor-connectors/"; then
              PACKAGES="$PACKAGES vendor-connectors"
            fi
          fi
          
          # Check docs
          if echo "$CHANGED_FILES" | grep -qE "docs/|\.rst$|\.md$|conf\.py$"; then
            DOCS_CHANGED="true"
          fi
          
          # Format output
          if [ -n "$PACKAGES" ]; then
            PACKAGES_JSON=$(echo $PACKAGES | tr ' ' '\n' | sort -u | grep -v '^$' | jq -R -s -c 'split("\n") | map(select(length > 0))')
            echo "any_changed=true" >> $GITHUB_OUTPUT
          else
            PACKAGES_JSON='[]'
            echo "any_changed=false" >> $GITHUB_OUTPUT
          fi
          
          echo "packages=$PACKAGES_JSON" >> $GITHUB_OUTPUT
          echo "docs_changed=$DOCS_CHANGED" >> $GITHUB_OUTPUT

  # ============================================
  # TEST
  # ============================================
  test:
    needs: changes
    if: needs.changes.outputs.any_changed == 'true'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        package: ${{ fromJson(needs.changes.outputs.packages) }}
        python: ['3.9', '3.13']
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - uses: astral-sh/setup-uv@v4

      - name: Cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: uv-${{ matrix.python }}-${{ hashFiles('uv.lock') }}

      - name: Install & Test
        run: |
          cd packages/${{ matrix.package }}
          
          # Install deps based on package
          case "${{ matrix.package }}" in
            extended-data-types)
              uv pip install -e ".[tests]" --system
              ;;
            lifecyclelogging)
              uv pip install -e ../extended-data-types --system
              uv pip install -e ".[tests]" --system
              ;;
            directed-inputs-class)
              uv pip install -e ../extended-data-types --system
              uv pip install -e ".[tests]" --system
              ;;
            vendor-connectors)
              uv pip install -e ../extended-data-types --system
              uv pip install -e ../lifecyclelogging --system
              uv pip install -e ".[tests]" --system
              ;;
          esac
          
          pytest tests -v --tb=short

  # ============================================
  # LINT
  # ============================================
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      
      - name: Lint
        run: |
          uv pip install ruff --system
          ruff check packages/
          ruff format --check packages/

  # ============================================
  # BUILD DOCS
  # ============================================
  docs:
    needs: changes
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - uses: astral-sh/setup-uv@v4

      - name: Build docs
        run: |
          uv pip install sphinx sphinx-rtd-theme myst-parser --system
          
          # Install all packages for API docs
          uv pip install -e packages/extended-data-types --system
          uv pip install -e packages/lifecyclelogging --system
          
          # Create combined docs site
          mkdir -p docs/_build
          
          # Build each package's docs if they exist
          for pkg in extended-data-types lifecyclelogging; do
            if [ -d "packages/$pkg/docs" ]; then
              echo "Building docs for $pkg"
              cd packages/$pkg/docs
              sphinx-build -b html . ../../_build/$pkg
              cd ../../..
            fi
          done
          
          # Create index
          cat > docs/_build/index.html << 'HTMLEOF'
          <!DOCTYPE html>
          <html>
          <head><title>jbcom Python Libraries</title></head>
          <body>
          <h1>jbcom Python Libraries</h1>
          <ul>
          <li><a href="extended-data-types/">extended-data-types</a></li>
          <li><a href="lifecyclelogging/">lifecyclelogging</a></li>
          </ul>
          </body>
          </html>
          HTMLEOF

      - name: Upload docs artifact
        uses: actions/upload-artifact@v4
        with:
          name: docs
          path: docs/_build/

  # ============================================
  # SYNC TO PUBLIC REPOS (main only)
  # ============================================
  sync:
    needs: [test, lint]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.CI_GITHUB_TOKEN }}

      - name: Sync to public repos
        uses: BetaHuhn/repo-file-sync-action@v1
        with:
          GH_PAT: ${{ secrets.CI_GITHUB_TOKEN }}
          CONFIG_PATH: .github/sync.yml
          SKIP_PR: true
          COMMIT_PREFIX: 'ðŸš€ Sync:'

  # ============================================
  # RELEASE TO PYPI (main only)
  # ============================================
  release:
    needs: [sync]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 1  # Release in order
      matrix:
        package:
          - name: extended-data-types
            path: packages/extended-data-types
            pypi: extended-data-types
          - name: lifecyclelogging
            path: packages/lifecyclelogging
            pypi: lifecyclelogging
          - name: directed-inputs-class
            path: packages/directed-inputs-class
            pypi: directed-inputs-class
          - name: vendor-connectors
            path: packages/vendor-connectors
            pypi: cloud-connectors
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Build & Release
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
        run: |
          pip install build twine pycalver
          
          # Bump version at workspace level
          pycalver bump --release final --no-commit --no-tag --no-push || true
          
          cd ${{ matrix.package.path }}
          python -m build
          twine upload dist/* --skip-existing
          
          echo "ðŸ“¦ Released ${{ matrix.package.pypi }}"

  # ============================================
  # DEPLOY DOCS (main only)
  # ============================================
  deploy-docs:
    needs: [docs, release]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          repository: ${{ env.DOCS_REPO }}
          token: ${{ secrets.CI_GITHUB_TOKEN }}
          path: docs-repo

      - name: Download docs
        uses: actions/download-artifact@v4
        with:
          name: docs
          path: new-docs

      - name: Push to docs repo
        run: |
          cd docs-repo
          rm -rf *
          cp -r ../new-docs/* .
          
          git config user.name "jbcom-bot"
          git config user.email "jbcom-bot@users.noreply.github.com"
          git add -A
          git diff --staged --quiet || git commit -m "ðŸ“š Update docs from control-center"
          git push
